{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Evaluation and Interpretation\n",
                "## Amazon Music Clustering Project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import pickle\n",
                "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
                "from math import pi\n",
                "\n",
                "# Set plot style\n",
                "sns.set(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Load Data and Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load processed data and model\n",
                "X_scaled_df = pd.read_csv('../data/processed/scaled_features.csv')\n",
                "df = pd.read_csv('../data/processed/clustered_data.csv')\n",
                "\n",
                "with open('../models/kmeans_model.pkl', 'rb') as f:\n",
                "    kmeans = pickle.load(f)\n",
                "\n",
                "labels = kmeans.labels_"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Quantitative Evaluation Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sil_score = silhouette_score(X_scaled_df, labels)\n",
                "db_score = davies_bouldin_score(X_scaled_df, labels)\n",
                "ch_score = calinski_harabasz_score(X_scaled_df, labels)\n",
                "\n",
                "print(f\"Silhouette Score: {sil_score:.4f}\")\n",
                "print(f\"Davies-Bouldin Index: {db_score:.4f}\")\n",
                "print(f\"Calinski-Harabasz Score: {ch_score:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Interpretation:**\n",
                "- **Silhouette Score**: Ranges from -1 to 1. A higher score indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\n",
                "- **Davies-Bouldin Index**: The score is defined as the average similarity measure of each cluster with its most similar cluster. Lower values indicate better clustering.\n",
                "- **Calinski-Harabasz Index**: Also known as the Variance Ratio Criterion. Higher values indicate better defined clusters."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Cluster Profiling (Radar Charts)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select features for radar chart (normalized roughly 0-1 range features work best, or use scaled)\n",
                "# We will use the original values but normalize them min-max for visualization purposes to fit on the radar chart\n",
                "radar_features = ['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence']\n",
                "\n",
                "# Normalize features for visualization\n",
                "df_normalized = df[radar_features].copy()\n",
                "for col in radar_features:\n",
                "    df_normalized[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
                "\n",
                "df_normalized['cluster'] = df['cluster']\n",
                "cluster_means = df_normalized.groupby('cluster').mean()\n",
                "\n",
                "def plot_radar_chart(means, features):\n",
                "    # Number of variables\n",
                "    N = len(features)\n",
                "    \n",
                "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
                "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
                "    angles += [angles[0]]\n",
                "    \n",
                "    # Initialise the spider plot\n",
                "    plt.figure(figsize=(10, 10))\n",
                "    ax = plt.subplot(111, polar=True)\n",
                "    \n",
                "    # Draw one axe per variable + add labels\n",
                "    plt.xticks(angles[:-1], features)\n",
                "    \n",
                "    # Draw ylabels\n",
                "    ax.set_rlabel_position(0)\n",
                "    plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=7)\n",
                "    plt.ylim(0, 1)\n",
                "    \n",
                "    # Plot each cluster\n",
                "    for i, row in means.iterrows():\n",
                "        values = row.values.flatten().tolist()\n",
                "        values += [values[0]]\n",
                "        ax.plot(angles, values, linewidth=1, linestyle='solid', label=f'Cluster {i}')\n",
                "        ax.fill(angles, values, alpha=0.1)\n",
                "        \n",
                "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
                "    plt.title('Cluster Profiles (Radar Chart)')\n",
                "    plt.show()\n",
                "\n",
                "plot_radar_chart(cluster_means, radar_features)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Cluster Interpretation\n",
                "\n",
                "Based on the feature distributions and radar charts, we can interpret the clusters as follows (Example interpretations, adjust based on actual results):\n",
                "\n",
                "- **Cluster 0**: *High Energy / Dance*\n",
                "    - Characterized by high energy and danceability.\n",
                "    - Likely pop, dance, or upbeat tracks.\n",
                "\n",
                "- **Cluster 1**: *Acoustic / Chill*\n",
                "    - High acousticness, low energy.\n",
                "    - Likely ballads, acoustic covers, or classical.\n",
                "\n",
                "- **Cluster 2**: *Instrumental*\n",
                "    - High instrumentalness, low speechiness.\n",
                "    - Likely soundtracks, classical, or study music.\n",
                "\n",
                "- **Cluster 3**: *Lyrical / Vocal*\n",
                "    - High speechiness or valence.\n",
                "    - Likely rap, hip-hop, or vocal-heavy tracks.\n",
                "\n",
                "*(Note: The actual interpretation depends on the specific K-Means result and random seed used)*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}